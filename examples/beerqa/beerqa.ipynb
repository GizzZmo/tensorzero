{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from tensorzero import AsyncTensorZeroGateway\n",
    "from tqdm.asyncio import trange\n",
    "from utils import BeerQA, confidence_interval, execute_tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beerqa = BeerQA(\"data/beerqa_dev_v1.0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorzero_semaphore = asyncio.Semaphore(10)\n",
    "wikipedia_semaphore = asyncio.Semaphore(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def solve_beerqa(\n",
    "    client: AsyncTensorZeroGateway,\n",
    "    question: str,\n",
    "    variant_name: str = \"baseline\",\n",
    "    query_budget: int = 3,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Solve a BeerQA question using Wikipedia.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "    for queries_remaining in range(query_budget, 0, -1):\n",
    "        async with tensorzero_semaphore:\n",
    "            response = await client.inference(\n",
    "                function_name=\"beerqa_solver\",\n",
    "                input={\n",
    "                    \"system\": {\"queries_remaining\": queries_remaining},\n",
    "                    \"messages\": messages,\n",
    "                },\n",
    "                variant_name=variant_name,\n",
    "            )\n",
    "        messages.append({\"role\": \"user\", \"content\": response.content})\n",
    "        for block in response.content:\n",
    "            if block.type == \"tool_call\":\n",
    "                if block.name == \"submit_answer\":\n",
    "                    return block.arguments[\"answer\"]\n",
    "                result = await execute_tool_call(block)\n",
    "                messages.append({\"role\": \"user\", \"content\": [result]})\n",
    "    async with tensorzero_semaphore:\n",
    "        response = await client.inference(\n",
    "            function_name=\"final_answer\",\n",
    "            input={\"system\": {\"question\": question}, \"messages\": messages},\n",
    "            variant_name=variant_name,\n",
    "        )\n",
    "    return response.output.parsed[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def grade_answer(\n",
    "    client: AsyncTensorZeroGateway,\n",
    "    question: str,\n",
    "    gt_answer: List[str],\n",
    "    submitted_answer: str,\n",
    ") -> float:\n",
    "    async with tensorzero_semaphore:\n",
    "        response = await client.inference(\n",
    "            function_name=\"grade_answer\",\n",
    "            input={\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": {\n",
    "                            \"question\": question,\n",
    "                            \"gt_answer\": gt_answer,\n",
    "                            \"submitted_answer\": submitted_answer,\n",
    "                        },\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "        )\n",
    "    return response.output.parsed[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def solve_grade_question(\n",
    "    client: AsyncTensorZeroGateway,\n",
    "    question: str,\n",
    "    gt_answer: List[str],\n",
    "    variant_name=\"baseline\",\n",
    "    query_budget: int = 3,\n",
    ") -> float:\n",
    "    submitted_answer = await solve_beerqa(\n",
    "        client, question, variant_name=variant_name, query_budget=query_budget\n",
    "    )\n",
    "    score = await grade_answer(client, question, gt_answer, submitted_answer)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_questions = 100\n",
    "scores = []\n",
    "\n",
    "async with AsyncTensorZeroGateway(\"http://localhost:3000\") as client:\n",
    "    tasks = []\n",
    "    for i in range(num_questions):\n",
    "        question = beerqa.get_question(i)\n",
    "        gt_answer = beerqa.get_answers(i)\n",
    "        tasks.append(\n",
    "            solve_grade_question(\n",
    "                client, question, gt_answer, variant_name=\"baseline\", query_budget=5\n",
    "            )\n",
    "        )\n",
    "\n",
    "    progress_bar = trange(num_questions, desc=\"Solving questions\")\n",
    "    for task in asyncio.as_completed(tasks):\n",
    "        score = await task\n",
    "        scores.append(score)\n",
    "        current = len(scores)\n",
    "        ci_lower, ci_upper = confidence_interval(scores)\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"Average Score\": f\"{np.mean(scores):.2f} CI: ({ci_lower:.2f}, {ci_upper:.2f})\"\n",
    "            },\n",
    "            refresh=True,\n",
    "        )\n",
    "    progress_bar.close()\n",
    "\n",
    "print(f\"Average score: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beerqa.get_answers(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
